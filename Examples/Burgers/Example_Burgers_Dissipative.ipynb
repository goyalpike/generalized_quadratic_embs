{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5499082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:14.304874Z",
     "iopub.status.busy": "2023-11-25T20:26:14.304473Z",
     "iopub.status.idle": "2023-11-25T20:26:15.097147Z",
     "shell.execute_reply": "2023-11-25T20:26:15.096661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/goyalp/Manuscripts/Year_2023/generalized_quad_embs\n",
      "/Users/goyalp/Manuscripts/Year_2023/generalized_quad_embs/data\n",
      "No GPU found!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch\n",
    "from scipy.io import savemat, loadmat\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "THIS_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PARENT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "sys.path.append(PARENT_DIR)\n",
    "\n",
    "import generalized_quad_embs.modules_quad_stable as module\n",
    "import generalized_quad_embs.plots_helper as plot\n",
    "from generalized_quad_embs import utils\n",
    "from generalized_quad_embs.constants import DATA_DIR\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device.type == \"cpu\":\n",
    "    print(\"No GPU found!\")\n",
    "else:\n",
    "    print(\"Great, a GPU is there\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Plotting setting\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = prop_cycle.by_key()[\"color\"]\n",
    "\n",
    "plt.rc(\"font\", size=20)  # controls default text size\n",
    "plt.rc(\"axes\", titlesize=20)  # fontsize of the title\n",
    "plt.rc(\"axes\", labelsize=20)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=20)  # fontsize of the x tick labels\n",
    "plt.rc(\"ytick\", labelsize=20)  # fontsize of the y tick labels\n",
    "plt.rc(\"legend\", fontsize=15)  # fontsize of the legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7270cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:15.099029Z",
     "iopub.status.busy": "2023-11-25T20:26:15.098946Z",
     "iopub.status.idle": "2023-11-25T20:26:15.101524Z",
     "shell.execute_reply": "2023-11-25T20:26:15.101283Z"
    }
   },
   "outputs": [],
   "source": [
    "## Define the parameters\n",
    "@dataclass\n",
    "class Parameters:\n",
    "    \"\"\"It contain necessary parameters for this example.\"\"\"\n",
    "\n",
    "    canonical_dim = 3  # canonical dimension\n",
    "    train_index = 600  # number of pts for training\n",
    "    latent_dim = 6  # latent canonical dimensional\n",
    "    hidden_dim = 16  # number of neurons in a hidden layer\n",
    "    batch_size = 64  # batch size\n",
    "    learning_rate = 5e-3  # Learning rate\n",
    "    encoder = \"MLP\"\n",
    "    confi_model: str = None  # model configuration\n",
    "    epoch: int = None  # number of epochs which are externally controlled\n",
    "    path: str = (\n",
    "        None  # path where the results will be save and it is also externally controlled\n",
    "    )\n",
    "    loss_weights: tuple = (10.0, 1.0)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72522a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:15.103229Z",
     "iopub.status.busy": "2023-11-25T20:26:15.103120Z",
     "iopub.status.idle": "2023-11-25T20:26:15.113469Z",
     "shell.execute_reply": "2023-11-25T20:26:15.113181Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_singular_values():\n",
    "    \"\"\"It is a helper function for plotting singular values.\"\"\"\n",
    "    plt.rc(\"font\", size=30)  # controls default text size\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    ax.semilogy(_S / _S[0])\n",
    "    ax.set(\n",
    "        ylabel=\"singular values (rel)\", xlabel=\"$k$\", xlim=(-1, 50), ylim=(1e-6, 2e0)\n",
    "    )\n",
    "    ax.grid()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(params.path + \"svd_plot.png\", dpi=300)\n",
    "    fig.savefig(params.path + \"svd_plot.pdf\")\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    Ssum = np.zeros_like(_S)\n",
    "    Ssum[0] = _S[0]\n",
    "    for i in range(len(_S[1:])):\n",
    "        Ssum[i] = sum(_S[: i + 1])\n",
    "\n",
    "    # plt.plot(_S)\n",
    "    ax.plot(list(range(1, len(_S) + 1)), Ssum / sum(_S))\n",
    "    ax.plot([3, 3], [0.05, 1.0], \"g--\")\n",
    "    ax.plot([-1, 50], [sum(_S[:3]) / sum(_S), sum(_S[:3]) / sum(_S)], \"g--\")\n",
    "\n",
    "    ax.set(ylabel=\"energy captured\", xlabel=\"$k$\", xlim=(-1, 20), ylim=(0.05, 1.05))\n",
    "    ax.set_xticks([0, 3, 5, 10, 15, 20])\n",
    "    ax.set_yticks([0.25, 0.527, 0.75, 1.0])\n",
    "    ax.grid()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(params.path + \"energy_plot.png\", dpi=300)\n",
    "    fig.savefig(params.path + \"energy_plot.pdf\")\n",
    "\n",
    "\n",
    "def POD_coeffs_plots():\n",
    "    \"\"\"It is a helper function to plot POD coefficients\n",
    "    (grouth truth as well as learned ones).\n",
    "    \"\"\"\n",
    "    fig1, ax1 = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    fig2, ax2 = plt.subplots(1, 1, figsize=(5, 3))\n",
    "\n",
    "    for k in range(data.shape[-1]):\n",
    "        ax1.plot(t, data[:, k].cpu())\n",
    "        ax2.plot(t, decoded_latent_sol[:, k].cpu())\n",
    "        ax1.set_ylim(-4.5, 4.5)\n",
    "        ax2.set_ylim(-4.5, 4.5)\n",
    "\n",
    "    ax1.set(xlabel=\"time\", ylabel=\"POD coeffs\")\n",
    "    ax2.set(xlabel=\"time\", ylabel=\"POD coeffs\")\n",
    "\n",
    "    fig1.savefig(\n",
    "        params.path + f\"pod_coeffs_ground_truth_{k}.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0.1,\n",
    "    )\n",
    "    fig1.savefig(\n",
    "        params.path + f\"pod_coeffs_ground_truth_{k}.pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0.1,\n",
    "    )\n",
    "\n",
    "    fig2.savefig(\n",
    "        params.path + f\"pod_coeffs_learned_{k}.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0.1,\n",
    "    )\n",
    "    fig2.savefig(\n",
    "        params.path + f\"pod_coeffs_learned_{k}.pdf\", bbox_inches=\"tight\", pad_inches=0.1\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_decoded_solution(save_plots=True):\n",
    "    \"\"\"It is a helper function to plot solutions on the full grid.\n",
    "\n",
    "    Args:\n",
    "        save_plots (bool, optional): It indicates whether to save plots or not. Defaults to True.\n",
    "    \"\"\"\n",
    "\n",
    "    def mycolorbar(ax):\n",
    "        fbar = fig.colorbar(\n",
    "            im,\n",
    "            ax=ax,\n",
    "            orientation=\"horizontal\",\n",
    "            pad=0.3,\n",
    "            format=\"%.1e\",\n",
    "            ticks=[\n",
    "                _min,\n",
    "                (2 / 3) * _min + (1 / 3) * _max,\n",
    "                (1 / 3) * _min + (2 / 3) * _max,\n",
    "                _max,\n",
    "            ],\n",
    "        )\n",
    "        tick_font_size = 13\n",
    "        fbar.ax.tick_params(labelsize=tick_font_size)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(18, 3), sharex=True, sharey=True)\n",
    "\n",
    "    _min, _max = np.min(q_data.T[:, ::1].numpy()), np.max(q_data.T[:, ::1].numpy())\n",
    "    im = axes[0].pcolormesh(\n",
    "        T[:, ::1], X[:, ::1], q_data.T[:, ::1], vmin=_min, vmax=_max\n",
    "    )\n",
    "\n",
    "    axes[0].set(title=\"ground truth\", xlabel=\"time\", ylabel=\"$q$\")\n",
    "    mycolorbar(axes[0])\n",
    "\n",
    "    _min, _max = np.min(q_pod.T[:, ::1].numpy()), np.max(q_pod.T[:, ::1].numpy())\n",
    "    im = axes[1].pcolormesh(T[:, ::1], X[:, ::1], q_pod.T[:, ::1], vmin=_min, vmax=_max)\n",
    "\n",
    "    axes[1].set(title=\" linear-decoder\", xlabel=\"time\")\n",
    "    mycolorbar(axes[1])\n",
    "\n",
    "    _min, _max = np.min(q_rec_quad.T[:, ::1].numpy()), np.max(\n",
    "        q_rec_quad.T[:, ::1].numpy()\n",
    "    )\n",
    "    im = axes[2].pcolormesh(\n",
    "        T[:, ::1], X[:, ::1], q_rec_quad.T[:, ::1], vmin=_min, vmax=_max\n",
    "    )\n",
    "\n",
    "    axes[2].set(title=\" quad-decoder\", xlabel=\"time\")\n",
    "    mycolorbar(axes[2])\n",
    "\n",
    "    _min, _max = np.min(q_rec.T[:, ::1].numpy()), np.max(q_rec.T[:, ::1].numpy())\n",
    "    im = axes[3].pcolormesh(T[:, ::1], X[:, ::1], q_rec.T[:, ::1], vmin=_min, vmax=_max)\n",
    "\n",
    "    mycolorbar(axes[3])\n",
    "    axes[3].set(title=\" convo-decoder\", xlabel=\"time\")\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0)\n",
    "\n",
    "    if save_plots:\n",
    "        plt.savefig(\n",
    "            params.path + f\"q_compare_{i}.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "            pad_inches=0.1,\n",
    "        )\n",
    "        # plt.savefig(\n",
    "        #     params.path + f\"q_compare_{i}.pdf\", bbox_inches=\"tight\", pad_inches=0.1\n",
    "        # )\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(18, 3), sharex=True, sharey=True)\n",
    "\n",
    "    _min, _max = np.min(p_data.T[:, ::1].numpy()), np.max(p_data.T[:, ::1].numpy())\n",
    "    im = axes[0].pcolormesh(\n",
    "        T[:, ::1], X[:, ::1], p_data.T[:, ::1], vmin=_min, vmax=_max\n",
    "    )\n",
    "\n",
    "    axes[0].set(title=\"ground truth\", xlabel=\"time\", ylabel=\"$p$\")\n",
    "    mycolorbar(axes[0])\n",
    "\n",
    "    _min, _max = np.min(p_pod.T[:, ::1].numpy()), np.max(p_pod.T[:, ::1].numpy())\n",
    "    im = axes[1].pcolormesh(T[:, ::1], X[:, ::1], p_pod.T[:, ::1], vmin=_min, vmax=_max)\n",
    "\n",
    "    axes[1].set(title=\" linear-decoder\", xlabel=\"time\")\n",
    "    mycolorbar(axes[1])\n",
    "\n",
    "    _min, _max = np.min(p_rec_quad.T[:, ::1].numpy()), np.max(\n",
    "        p_rec_quad.T[:, ::1].numpy()\n",
    "    )\n",
    "    im = axes[2].pcolormesh(\n",
    "        T[:, ::1], X[:, ::1], p_rec_quad.T[:, ::1], vmin=_min, vmax=_max\n",
    "    )\n",
    "\n",
    "    axes[2].set(title=\" quad-decoder\", xlabel=\"time\")\n",
    "    mycolorbar(axes[2])\n",
    "\n",
    "    _min, _max = np.min(p_rec.T[:, ::1].numpy()), np.max(p_rec.T[:, ::1].numpy())\n",
    "    im = axes[3].pcolormesh(T[:, ::1], X[:, ::1], p_rec.T[:, ::1], vmin=_min, vmax=_max)\n",
    "\n",
    "    mycolorbar(axes[3])\n",
    "    axes[3].set(title=\" convo-decoder\", xlabel=\"time\")\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0)\n",
    "\n",
    "    if save_plots:\n",
    "        plt.savefig(\n",
    "            params.path + f\"p_compare_{i}.png\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "            pad_inches=0.1,\n",
    "        )\n",
    "        # plt.savefig(\n",
    "        #     params.path + f\"p_compare_{i}.pdf\", bbox_inches=\"tight\", pad_inches=0.1\n",
    "        # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64b434f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:15.114983Z",
     "iopub.status.busy": "2023-11-25T20:26:15.114896Z",
     "iopub.status.idle": "2023-11-25T20:26:15.118002Z",
     "shell.execute_reply": "2023-11-25T20:26:15.117719Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.reproducibility_seed(seed=100)\n",
    "\n",
    "params = Parameters()\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--confi_model\",\n",
    "    type=str,\n",
    "    default=\"quad\",\n",
    "    choices={\"linear\", \"quad\", \"cubic\", \"linear_nostability\", \"quad_opinf\"},\n",
    "    help=\"Enforcing model hypothesis\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--epochs\", type=int, default=400, help=\"Number of epochs\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "params.confi_model = args.confi_model\n",
    "params.epoch = args.epochs\n",
    "\n",
    "params.path = \"./../Results/Burgers/\" + params.confi_model + \"/\"\n",
    "\n",
    "if not os.path.exists(params.path):\n",
    "    os.makedirs(params.path)\n",
    "    print(\"The new directory is created as \" + params.path)\n",
    "\n",
    "color_idx, method_name = utils.define_color_method(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97147b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# file_mat = \"/Users/goyalp/Manuscripts/Year_2023/generalized_quad_embs/data/Burgers_dirichilet_data.mat\"\n",
    "# with h5py.File(file_mat, 'r') as f:\n",
    "#     print(list(f.keys()))  # to inspect contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "189a0b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:15.119527Z",
     "iopub.status.busy": "2023-11-25T20:26:15.119385Z",
     "iopub.status.idle": "2023-11-25T20:26:15.166839Z",
     "shell.execute_reply": "2023-11-25T20:26:15.166373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 256, 1001)\n",
      "Training trajectories: (9, 256, 1001)\n",
      "Testing trajectories:  (4, 256, 1001)\n",
      "\n",
      "shape of X for training:\t(9, 256, 1001)\n",
      "Training samples: 9\n"
     ]
    }
   ],
   "source": [
    "# ## Loading data\n",
    "# data = loadmat(\"./Burgers_dirichilet_data.mat\")\n",
    "# data = loadmat(str(DATA_DIR / \"Burgers_dirichilet_data.mat\"))\n",
    "data = loadmat(\"/Users/goyalp/Manuscripts/Year_2023/generalized_quad_embs/data/Burgers_dirichilet_data.mat\")\n",
    "X_all = data[\"X_data\"].transpose(0, 2, 1)[:,::1,:]\n",
    "dX_all = data[\"dX_data\"].transpose(0, 2, 1)[:,::1,:]\n",
    "\n",
    "print(X_all.shape)\n",
    "x_shift = 0 * np.ones((1, X_all.shape[1], 1))\n",
    "X_all = X_all - x_shift\n",
    "\n",
    "idxs = list(np.arange(0, 13))\n",
    "testing_idxs = list([2, 5, 8, 11])\n",
    "train_idxs = list(set(idxs) - set(testing_idxs))\n",
    "# train_idxs = testing_idxs\n",
    "\n",
    "# testing_idxs = list([2])\n",
    "# train_idxs = testing_idxs\n",
    "\n",
    "X_testing = X_all[testing_idxs]\n",
    "X_training = X_all[train_idxs]\n",
    "\n",
    "dX_testing = dX_all[testing_idxs]\n",
    "dX_training = dX_all[train_idxs]\n",
    "\n",
    "\n",
    "t = data[\"t\"].T\n",
    "print(f\"Training trajectories: {X_training.shape}\")\n",
    "print(f\"Testing trajectories:  {X_testing.shape}\\n\")\n",
    "\n",
    "num_inits = X_training.shape[0]\n",
    "print(f\"shape of X for training:\\t{X_training.shape}\")\n",
    "print(f\"Training samples: {num_inits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d409488a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:15.168718Z",
     "iopub.status.busy": "2023-11-25T20:26:15.168360Z",
     "iopub.status.idle": "2023-11-25T20:26:16.541334Z",
     "shell.execute_reply": "2023-11-25T20:26:16.541052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domainant model for first: 11\n",
      "Energy captured by the snapshots: 90.8740314568382%\n"
     ]
    }
   ],
   "source": [
    "# Compute SVD in order to prepare low-dimensional data\n",
    "\n",
    "temp_X = np.hstack(X_training)\n",
    "[U, S, V] = np.linalg.svd(temp_X)\n",
    "\n",
    "temp_dX = np.hstack(dX_training)\n",
    "\n",
    "tol = 1e-1\n",
    "reduced_orders = []\n",
    "\n",
    "[U, S, V] = np.linalg.svd(temp_X)\n",
    "r = 1\n",
    "while r < len(S) + 1:\n",
    "    if 1 - sum(S[:r]) / sum(S) < tol:\n",
    "        break\n",
    "    r += 1\n",
    "    \n",
    "print(f\"Domainant model for first: {r}\")\n",
    "print(f\"Energy captured by the snapshots: {100*sum(S[:r])/sum(S)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658041ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:16.542782Z",
     "iopub.status.busy": "2023-11-25T20:26:16.542640Z",
     "iopub.status.idle": "2023-11-25T20:26:16.574909Z",
     "shell.execute_reply": "2023-11-25T20:26:16.574568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proj matrix shape: (256, 256)\n"
     ]
    }
   ],
   "source": [
    "params.canonical_dim = 256\n",
    "params.latent_dim = 4\n",
    "\n",
    "\n",
    "Projection_V = np.eye(256,256)\n",
    "r = 256\n",
    "print(f\"Proj matrix shape: {Projection_V.shape}\")\n",
    "temp_Xr = Projection_V.T @ temp_X  # reduced data\n",
    "temp_dXr = Projection_V.T @ temp_dX  # reduced data\n",
    "\n",
    "\n",
    "fac = abs(temp_Xr).max()\n",
    "fac = 1\n",
    "temp_Xr = temp_Xr/fac\n",
    "\n",
    "Xr = np.zeros((num_inits, r, temp_Xr.shape[-1] // num_inits))\n",
    "dXr = np.zeros((num_inits, r, temp_Xr.shape[-1] // num_inits))\n",
    "\n",
    "for i in range(0, num_inits):\n",
    "    temp = int(temp_Xr.shape[-1] // num_inits)\n",
    "    temp_x = temp_Xr[:, i * temp : (i + 1) * temp]\n",
    "    temp_dx = temp_dXr[:, i * temp : (i + 1) * temp]\n",
    "#     temp_dx = utils.ddt_uniform(temp_x, (t[1] - t[0]).item(), order=4)\n",
    "    Xr[i] = temp_x\n",
    "    dXr[i] = temp_dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a9f7939",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:16.576573Z",
     "iopub.status.busy": "2023-11-25T20:26:16.576491Z",
     "iopub.status.idle": "2023-11-25T20:26:17.195887Z",
     "shell.execute_reply": "2023-11-25T20:26:17.195390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 256, 1001)\n",
      "(9, 256, 1001)\n"
     ]
    }
   ],
   "source": [
    "# to remove edge points since derivatives are not accutate therein.\n",
    "Xr = Xr[:,:,:]\n",
    "dXr = dXr[:,:,:]\n",
    "print(Xr.shape)\n",
    "print(dXr.shape)\n",
    "\n",
    "Xr_v = np.hstack(Xr).T\n",
    "dXr_v = np.hstack(dXr).T\n",
    "\n",
    "train_dset = list(zip(torch.tensor(Xr_v).double().to(device).requires_grad_(), torch.tensor(dXr_v).double().to(device)))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_dset, batch_size = params.batch_size, shuffle = True)\n",
    "dataloaders = {'train': train_dl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea5b8174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:17.197689Z",
     "iopub.status.busy": "2023-11-25T20:26:17.197626Z",
     "iopub.status.idle": "2023-11-25T20:26:17.241012Z",
     "shell.execute_reply": "2023-11-25T20:26:17.240561Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AutoencoderConvo(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=1, out_channels=4, kernel_size=5, stride=2, padding=2\n",
    "        )\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=4, out_channels=8, kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv1d(\n",
    "            in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "        self.conv4 = nn.Conv1d(\n",
    "            in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1\n",
    "        )\n",
    "        self.linear_e1 = nn.Linear(in_features=512, out_features=32)\n",
    "        self.linear_e2 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.linear_e3 = nn.Linear(in_features=32, out_features=latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.linear_d1 = nn.Linear(in_features=latent_dim + latent_dim**2, out_features=32)\n",
    "        self.linear_d2 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.linear_d3 = nn.Linear(in_features=32, out_features=512)\n",
    "        self.deconv1 = nn.ConvTranspose1d(\n",
    "            in_channels=32,\n",
    "            out_channels=16,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "        )\n",
    "        self.deconv2 = nn.ConvTranspose1d(\n",
    "            in_channels=16,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "        )\n",
    "        self.deconv3 = nn.ConvTranspose1d(\n",
    "            in_channels=8,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "        )\n",
    "        self.deconv4 = nn.ConvTranspose1d(\n",
    "            in_channels=8,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "        )\n",
    "        self.deconv5 = nn.Conv1d(\n",
    "            in_channels=8,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "#             output_padding=1,\n",
    "        )\n",
    "        \n",
    "\n",
    "    def encode(self, x):\n",
    "        h = x.reshape(x.shape[0],1,x.shape[1])\n",
    "#         print(f'reshape step: {h.shape}')\n",
    "        h = self.conv1(h)\n",
    "        h = F.selu_(h)\n",
    "#         print(f'after conv1: {h.shape}')\n",
    "        h = self.conv2(h)\n",
    "        h = F.selu_(h)\n",
    "#         print(f'after conv2: {h.shape}')\n",
    "        h = self.conv3(h)\n",
    "        h = F.selu_(h)\n",
    "#         print(f'after conv3: {h.shape}')\n",
    "        h = self.conv4(h)\n",
    "        h = F.selu_(h)\n",
    "#         print(f'after conv4: {h.shape}')\n",
    "        h = nn.Flatten()(h)\n",
    "#         print(f'after flattening: {h.shape}')\n",
    "        h =  F.selu_(self.linear_e1(h))\n",
    "#         print(f'after linear_e1: {h.shape}')\n",
    "        h = h + F.selu_(self.linear_e2(h))\n",
    "#         print(f'after linear_e2: {h.shape}')\n",
    "        h = self.linear_e3(h)\n",
    "#         print(f'after linear_e3: {h.shape}')\n",
    "        \n",
    "        return h\n",
    "\n",
    "    def decode(self, z):\n",
    "        z2 = utils.kron(z, z) \n",
    "        z_all = torch.concat((z,z2), dim = -1)\n",
    "#         print(f'z2 shape: {z2.shape} | z_all  shape: {z_all.shape}')\n",
    "        h = self.linear_d1(z_all)\n",
    "#         h = h + F.selu_(h)\n",
    "#         print(f'after linear_d1: {h.shape}')\n",
    "        h = h + F.selu_(self.linear_d2(h))\n",
    "#         print(f'after linear_d2: {h.shape}')\n",
    "        h = F.selu_(self.linear_d3(h))\n",
    "#         print(f'after linear_d3: {h.shape}')\n",
    "        h = h.reshape(h.shape[0], 32, 16)\n",
    "#         print(f'after reshape: {h.shape}')\n",
    "\n",
    "        h = self.deconv1(h)\n",
    "        h = F.selu_(h)\n",
    "#         print(f'after deconv1: {h.shape}')\n",
    "\n",
    "        h = self.deconv2(h)\n",
    "        h = F.selu_(h)\n",
    "#         print(f'after deconv2: {h.shape}')\n",
    "        h = self.deconv3(h)\n",
    "        h = F.selu_(h)\n",
    "#         print(f'after deconv3: {h.shape}')\n",
    "        h = self.deconv4(h)\n",
    "        h = F.selu_(h)\n",
    "#         print(f'after deconv4: {h.shape}')\n",
    "        h = self.deconv5(h)\n",
    "#         print(f'after deconv5: {h.shape}')\n",
    "        h = nn.Flatten()(h)\n",
    "#         print(f'after flattening: {h.shape}')\n",
    "        return h\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f7e8a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:17.242660Z",
     "iopub.status.busy": "2023-11-25T20:26:17.242584Z",
     "iopub.status.idle": "2023-11-25T20:26:17.663243Z",
     "shell.execute_reply": "2023-11-25T20:26:17.662918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, dx = next(iter(train_dl))\n",
    "print(x.shape)\n",
    "models_conv = AutoencoderConvo(latent_dim=4).double().to(device)\n",
    "models_conv(x.double().to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd74a4de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:17.664924Z",
     "iopub.status.busy": "2023-11-25T20:26:17.664840Z",
     "iopub.status.idle": "2023-11-25T20:26:17.667221Z",
     "shell.execute_reply": "2023-11-25T20:26:17.666943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.concat>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9d15f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:17.668648Z",
     "iopub.status.busy": "2023-11-25T20:26:17.668527Z",
     "iopub.status.idle": "2023-11-25T20:26:17.672597Z",
     "shell.execute_reply": "2023-11-25T20:26:17.672347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear autoencoder and quadratic system with Gaurantee stability!\n",
      "Global Stability Gurantees!\n",
      "B_term: False\n"
     ]
    }
   ],
   "source": [
    "models = module.network_models(params)\n",
    "models['ae'] = AutoencoderConvo(latent_dim=4).double().to(device)\n",
    "optim = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": models[\"ae\"].parameters(),\n",
    "            \"lr\": params.learning_rate,\n",
    "            \"weight_decay\": 1e-5,\n",
    "        },\n",
    "        {\n",
    "            \"params\": models[\"vf\"].parameters(),\n",
    "            \"lr\": params.learning_rate,\n",
    "            \"weight_decay\": 1e-5,\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9235ee60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:17.673906Z",
     "iopub.status.busy": "2023-11-25T20:26:17.673810Z",
     "iopub.status.idle": "2023-11-25T20:26:17.675643Z",
     "shell.execute_reply": "2023-11-25T20:26:17.675469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoencoderConvo(\n",
       "  (conv1): Conv1d(1, 4, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "  (conv2): Conv1d(4, 8, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (conv3): Conv1d(8, 16, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (conv4): Conv1d(16, 32, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (linear_e1): Linear(in_features=512, out_features=32, bias=True)\n",
       "  (linear_e2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (linear_e3): Linear(in_features=32, out_features=4, bias=True)\n",
       "  (linear_d1): Linear(in_features=20, out_features=32, bias=True)\n",
       "  (linear_d2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (linear_d3): Linear(in_features=32, out_features=512, bias=True)\n",
       "  (deconv1): ConvTranspose1d(32, 16, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "  (deconv2): ConvTranspose1d(16, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "  (deconv3): ConvTranspose1d(8, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "  (deconv4): ConvTranspose1d(8, 8, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "  (deconv5): Conv1d(8, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['ae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb54a57e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T20:26:17.676888Z",
     "iopub.status.busy": "2023-11-25T20:26:17.676796Z",
     "iopub.status.idle": "2023-11-25T22:10:55.597727Z",
     "shell.execute_reply": "2023-11-25T22:10:55.597345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function from train_quad_conv\n",
      "Training begins!\n",
      "weights for loss function are: (10.0, 1.0)\n",
      "Epoch 1/400 | loss_VF: 1.37e-03 | loss_AE: 1.10e-01 | learning rate: 5.00e-03\n",
      "Epoch 2/400 | loss_VF: 7.84e-05 | loss_AE: 1.15e-01 | learning rate: 5.00e-03\n",
      "Epoch 3/400 | loss_VF: 1.94e-05 | loss_AE: 8.93e-02 | learning rate: 5.00e-03\n",
      "Epoch 4/400 | loss_VF: 5.44e-05 | loss_AE: 7.90e-02 | learning rate: 5.00e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %%prun\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m models, err_t \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_quad_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Manuscripts/Year_2023/generalized_quad_embs/generalized_quad_embs/modules_quad_stable.py:676\u001b[0m, in \u001b[0;36mtrain_quad_conv\u001b[0;34m(models, train_dl, optim, params)\u001b[0m\n\u001b[1;32m    670\u001b[0m     loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    671\u001b[0m         loss_weights[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m loss_ae\n\u001b[1;32m    672\u001b[0m         \u001b[38;5;241m+\u001b[39m loss_weights[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m loss_vf\n\u001b[1;32m    673\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m \u001b[38;5;241m*\u001b[39m (models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39m_H_tensor)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    674\u001b[0m     )\n\u001b[1;32m    675\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 676\u001b[0m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    678\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Manuscripts/Year_2023/generalized_quad_embs/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Manuscripts/Year_2023/generalized_quad_embs/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:109\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Manuscripts/Year_2023/generalized_quad_embs/.venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Manuscripts/Year_2023/generalized_quad_embs/.venv/lib/python3.10/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Manuscripts/Year_2023/generalized_quad_embs/.venv/lib/python3.10/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Manuscripts/Year_2023/generalized_quad_embs/.venv/lib/python3.10/site-packages/torch/optim/adam.py:307\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    309\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%prun\n",
    "models, err_t = module.train_quad_conv(models, train_dl, optim, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefc1d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:10:55.599325Z",
     "iopub.status.busy": "2023-11-25T22:10:55.599250Z",
     "iopub.status.idle": "2023-11-25T22:10:55.601131Z",
     "shell.execute_reply": "2023-11-25T22:10:55.600852Z"
    }
   },
   "outputs": [],
   "source": [
    "import profile\n",
    "pr = profile.Profile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f7dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:10:55.602578Z",
     "iopub.status.busy": "2023-11-25T22:10:55.602472Z",
     "iopub.status.idle": "2023-11-25T22:10:55.606014Z",
     "shell.execute_reply": "2023-11-25T22:10:55.605790Z"
    }
   },
   "outputs": [],
   "source": [
    "PROPERTY = {\n",
    "    \"cmap\": cm.viridis,\n",
    "    \"antialiased\": True,\n",
    "    \"rcount\": 500,\n",
    "    \"ccount\": 500,\n",
    "    \"linewidth\": 0,\n",
    "}\n",
    "\n",
    "def plotting_chafee():\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(16, 4), subplot_kw={\"projection\": \"3d\"})\n",
    "    # Plot the surface.\n",
    "    surf = ax[0].plot_surface(\n",
    "        space_grid,\n",
    "        time_grid,\n",
    "        (X_testing[k] + x_shift.reshape(-1, 1)).T,\n",
    "        **PROPERTY,\n",
    "    )\n",
    "    surf = ax[1].plot_surface(\n",
    "        space_grid,\n",
    "        time_grid,\n",
    "        (full_sol_OpInf + x_shift.reshape(-1, 1)).T,\n",
    "        **PROPERTY,\n",
    "    )\n",
    "    surf = ax[2].plot_surface(\n",
    "        space_grid,\n",
    "        time_grid,\n",
    "        np.log10(abs((X_testing[k] - full_sol_OpInf).T)),\n",
    "        **PROPERTY,\n",
    "    )\n",
    "    ax[0].set(xlabel=\"$x$\", ylabel=\"time\", zlabel=\"$u(x,t)$\", title=\"groundtruth\")\n",
    "\n",
    "    ax[1].set(\n",
    "        xlabel=\"$x$\",\n",
    "        ylabel=\"time\",\n",
    "        zlabel=\"$\\hat{u}(x,t)$\",\n",
    "        title=\"learned model\",\n",
    "    )\n",
    "    ax[2].set(\n",
    "        xlabel=\"$x$\",\n",
    "        ylabel=\"time\",\n",
    "        zlabel=\"error in log-scale\",\n",
    "        title=\"absolute error\",\n",
    "    )\n",
    "\n",
    "#     ax[0].set_zlim([0, 1.25])\n",
    "#     ax[1].set_zlim([0, 1.25])\n",
    "\n",
    "    for _ax in ax:\n",
    "        _ax.xaxis.labelpad = 10\n",
    "        _ax.yaxis.labelpad = 20\n",
    "        _ax.zaxis.labelpad = 10\n",
    "\n",
    "    ax[2].tick_params(axis=\"z\", direction=\"out\", pad=10)\n",
    "    ax[2].zaxis.labelpad = 20\n",
    "\n",
    "    ax[2].set_zscale(\"linear\")\n",
    "\n",
    "    plt.tight_layout(pad=0.2, w_pad=0.1, h_pad=0.1)\n",
    "\n",
    "    # plt.show()\n",
    "    # fig.savefig(\n",
    "    #     params.path + f\"simulation_test_{k}_order_{r}.pdf\",\n",
    "    #     bbox_inches=\"tight\",\n",
    "    #     pad_inches=0,\n",
    "    # )\n",
    "    fig.savefig(\n",
    "        params.path + f\"simulation_test_{k}_order_{r}.png\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6c4c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:10:55.607330Z",
     "iopub.status.busy": "2023-11-25T22:10:55.607236Z",
     "iopub.status.idle": "2023-11-25T22:10:55.608684Z",
     "shell.execute_reply": "2023-11-25T22:10:55.608473Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extracting autoencoder and hnn (hamiltonian)\n",
    "autoencoder, vf = models[\"ae\"], models[\"vf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58982c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:10:55.609820Z",
     "iopub.status.busy": "2023-11-25T22:10:55.609728Z",
     "iopub.status.idle": "2023-11-25T22:10:55.611526Z",
     "shell.execute_reply": "2023-11-25T22:10:55.611314Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare learned models for integration\n",
    "def learned_model(t, x):\n",
    "    \"\"\"It yields time-derivative of x at time t.\n",
    "    It is obtained throught the time-derivative of Hamiltonian function.\n",
    "\n",
    "    Args:\n",
    "        t (float): time\n",
    "        x (float): state variable containing position and momenta.\n",
    "\n",
    "    Returns:\n",
    "        float: time-derivative of x\n",
    "    \"\"\"\n",
    "    x = torch.tensor(\n",
    "        x.reshape(-1, params.latent_dim), dtype=torch.float64, requires_grad=True\n",
    "    ).to(device)\n",
    "    y = vf.vector_field(x)\n",
    "    y = y.detach()\n",
    "    return y.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebfbbd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:10:55.612828Z",
     "iopub.status.busy": "2023-11-25T22:10:55.612709Z",
     "iopub.status.idle": "2023-11-25T22:12:13.082564Z",
     "shell.execute_reply": "2023-11-25T22:12:13.082221Z"
    }
   },
   "outputs": [],
   "source": [
    "models['vf'] = models['vf'].to(device)\n",
    "\n",
    "t = np.arange(0, len(t)) * (t[1] - t[0])\n",
    "\n",
    "# testing learned model\n",
    "space = np.arange(0, 1, 1 / 256)\n",
    "time = np.array(data[\"t\"].T)\n",
    "space_grid, time_grid = np.meshgrid(space, time)\n",
    "\n",
    "Err_testing = []\n",
    "Learned_sols = []\n",
    "Truth_sols = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k in range(X_testing.shape[0]):\n",
    "        y0_test = Projection_V.T @ X_testing[k, :, 0]/fac\n",
    "        encoded_initial = autoencoder.encode(torch.from_numpy(y0_test)[None].to(device)).reshape(-1,).detach().cpu()\n",
    "        print(f'Initial condition encoded: {encoded_initial.shape}')\n",
    "\n",
    "        sol_OpInf = solve_ivp(learned_model, [t[0], t[-1]], y0=encoded_initial, \n",
    "                              t_eval=t, rtol = 1e-8, atol = 1e-8)\n",
    "        \n",
    "        sol_OpInf = torch.tensor(sol_OpInf.y, dtype=torch.float64).to(device)\n",
    "        decoded_latent_sol = autoencoder.decode(sol_OpInf.T).detach().cpu().numpy()\n",
    "        print(f'decoded solution: {decoded_latent_sol.shape}')\n",
    "\n",
    "        full_sol_OpInf = fac*Projection_V @ decoded_latent_sol.T\n",
    "\n",
    "        plotting_chafee()\n",
    "        err = (np.linalg.norm(full_sol_OpInf - X_testing[k])) / (\n",
    "            np.linalg.norm(X_testing[k])\n",
    "        )\n",
    "        print(abs(full_sol_OpInf - X_testing[k]).max())\n",
    "        print(f'test {k} error: {err}')\n",
    "        \n",
    "        Err_testing.append(err)\n",
    "        Truth_sols.append(X_testing[k])\n",
    "        Learned_sols.append(full_sol_OpInf)\n",
    "    savemat(params.path + f\"simulation_error_order_{r}.mat\",  {\"errors\": Err_testing, \n",
    "                                                                \"learned_sols\":Learned_sols,\n",
    "                                                                \"truth_sols\": Truth_sols\n",
    "                                                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44499a30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:12:13.083940Z",
     "iopub.status.busy": "2023-11-25T22:12:13.083872Z",
     "iopub.status.idle": "2023-11-25T22:12:13.086300Z",
     "shell.execute_reply": "2023-11-25T22:12:13.086017Z"
    }
   },
   "outputs": [],
   "source": [
    "Err_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c766134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:12:13.087639Z",
     "iopub.status.busy": "2023-11-25T22:12:13.087497Z",
     "iopub.status.idle": "2023-11-25T22:12:13.089359Z",
     "shell.execute_reply": "2023-11-25T22:12:13.089087Z"
    }
   },
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be9929",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:12:13.090615Z",
     "iopub.status.busy": "2023-11-25T22:12:13.090521Z",
     "iopub.status.idle": "2023-11-25T22:12:13.099645Z",
     "shell.execute_reply": "2023-11-25T22:12:13.099462Z"
    }
   },
   "outputs": [],
   "source": [
    "models['ae'].linear_e1.weight, models['ae'].linear_e1.weight.sum(), models['ae'].linear_e1.weight.abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d751306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:12:13.100863Z",
     "iopub.status.busy": "2023-11-25T22:12:13.100800Z",
     "iopub.status.idle": "2023-11-25T22:12:13.102658Z",
     "shell.execute_reply": "2023-11-25T22:12:13.102344Z"
    }
   },
   "outputs": [],
   "source": [
    "models['ae'].linear_d1.weight, models['ae'].linear_d1.weight.sum(), models['ae'].linear_d1.weight.abs().sum();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece75644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:12:13.103826Z",
     "iopub.status.busy": "2023-11-25T22:12:13.103763Z",
     "iopub.status.idle": "2023-11-25T22:12:13.106651Z",
     "shell.execute_reply": "2023-11-25T22:12:13.106400Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_quad_finetuning(models, pre_trained_model,  train_dl, optim, params):\n",
    "    \"\"\"It does training to learn vector field for the systems that are canonical\n",
    "\n",
    "    Args:\n",
    "        models (nn.module): models containing autoencoder and Hamiltonian networks\n",
    "        train_dl (dataloder): training data\n",
    "        optim (optimizer): optmizer to update parameters of neural networks\n",
    "        params (dataclass): contains necessary parameter e.g., number of epochs\n",
    "\n",
    "    Returns:\n",
    "        (model, loss): trained model and loss as training progresses\n",
    "    \"\"\"\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optim, step_size=150 * len(train_dl), gamma=0.1\n",
    "    )\n",
    "\n",
    "    print(\"Training begins!\")\n",
    "\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    err_t = []\n",
    "    for i in range(params.epoch):\n",
    "\n",
    "        for x, dxdt in train_dl:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                z = pre_trained_model[\"ae\"].encode(x)\n",
    "            x_hat = models[\"ae\"].decode(z)\n",
    "            loss_ae = 0.5 * mse_loss(x_hat, x)  # Encoder loss\n",
    "            loss_ae += 0.5 * (x_hat - x).abs().mean()  # Encoder loss\n",
    "\n",
    "            loss = 1e1*loss_ae\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            scheduler.step()\n",
    "            err_t.append(loss.item())\n",
    "\n",
    "        if (i + 1) % 1 == 0:\n",
    "            lr = optim.param_groups[0][\"lr\"]\n",
    "            print(\n",
    "                f\"Epoch {i+1}/{params.epoch} | loss_AE: {loss_ae.item():.2e} | learning rate: {lr:.2e}\"\n",
    "            )\n",
    "    return models, err_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fef2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:12:13.107842Z",
     "iopub.status.busy": "2023-11-25T22:12:13.107778Z",
     "iopub.status.idle": "2023-11-25T22:51:18.007145Z",
     "shell.execute_reply": "2023-11-25T22:51:18.006710Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "models_finetune = module.network_models(params)\n",
    "models_finetune['ae'] = AutoencoderConvo(latent_dim=4).double().to(device)\n",
    "\n",
    "sd = models['ae'].state_dict()\n",
    "models_finetune['ae'].load_state_dict(copy.deepcopy(sd))\n",
    "\n",
    "optim_finetune = torch.optim.Adam(\n",
    "    [\n",
    "        {\n",
    "            \"params\": models_finetune[\"ae\"].parameters(),\n",
    "            \"lr\": params.learning_rate,\n",
    "            \"weight_decay\": 1e-6,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "models_finetune, err_finetune = train_quad_finetuning(models_finetune, models, train_dl, optim_finetune, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9442ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:51:18.008670Z",
     "iopub.status.busy": "2023-11-25T22:51:18.008589Z",
     "iopub.status.idle": "2023-11-25T22:51:18.012840Z",
     "shell.execute_reply": "2023-11-25T22:51:18.012626Z"
    }
   },
   "outputs": [],
   "source": [
    "models['ae'].linear_e1.weight, models['ae'].linear_e1.weight.sum(), models['ae'].linear_e1.weight.abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0746d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:51:18.013990Z",
     "iopub.status.busy": "2023-11-25T22:51:18.013927Z",
     "iopub.status.idle": "2023-11-25T22:51:18.017055Z",
     "shell.execute_reply": "2023-11-25T22:51:18.016836Z"
    }
   },
   "outputs": [],
   "source": [
    "#verify\n",
    "for name, param in models['ae'].named_parameters():\n",
    "    print(name,param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a18d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:51:18.018310Z",
     "iopub.status.busy": "2023-11-25T22:51:18.018207Z",
     "iopub.status.idle": "2023-11-25T22:51:18.019608Z",
     "shell.execute_reply": "2023-11-25T22:51:18.019437Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder_finetune = models_finetune['ae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795207c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:51:18.020782Z",
     "iopub.status.busy": "2023-11-25T22:51:18.020683Z",
     "iopub.status.idle": "2023-11-25T22:52:37.091932Z",
     "shell.execute_reply": "2023-11-25T22:52:37.091431Z"
    }
   },
   "outputs": [],
   "source": [
    "models['vf'] = models['vf'].to(device)\n",
    "\n",
    "t = np.arange(0, len(t)) * (t[1] - t[0])\n",
    "\n",
    "# testing learned model\n",
    "space = np.arange(0, 1, 1 / 256)\n",
    "time = np.array(data[\"t\"].T)\n",
    "space_grid, time_grid = np.meshgrid(space, time)\n",
    "\n",
    "Err_testing = []\n",
    "Learned_sols = []\n",
    "Truth_sols = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k in range(X_testing.shape[0]):\n",
    "        y0_test = Projection_V.T @ X_testing[k, :, 0]/fac\n",
    "        encoded_initial = autoencoder.encode(torch.from_numpy(y0_test)[None].to(device)).reshape(-1,).detach().cpu()\n",
    "        print(f'Initial condition encoded: {encoded_initial.shape}')\n",
    "\n",
    "        sol_OpInf = solve_ivp(learned_model, [t[0], t[-1]], y0=encoded_initial, \n",
    "                              t_eval=t, rtol = 1e-8, atol = 1e-8)\n",
    "        \n",
    "        sol_OpInf = torch.tensor(sol_OpInf.y, dtype=torch.float64).to(device)\n",
    "        decoded_latent_sol = autoencoder_finetune.decode(sol_OpInf.T).detach().cpu().numpy()\n",
    "        print(f'decoded solution: {decoded_latent_sol.shape}')\n",
    "\n",
    "        full_sol_OpInf = fac*Projection_V @ decoded_latent_sol.T\n",
    "\n",
    "        plotting_chafee()\n",
    "        err = (np.linalg.norm(full_sol_OpInf - X_testing[k])) / (\n",
    "            np.linalg.norm(X_testing[k])\n",
    "        )\n",
    "        print(abs(full_sol_OpInf - X_testing[k]).max())\n",
    "        print(f'test {k} error: {err}')\n",
    "        Err_testing.append(err)\n",
    "        Truth_sols.append(X_testing[k])\n",
    "        Learned_sols.append(full_sol_OpInf)\n",
    "    savemat(params.path + f\"simulation_error_order_{r}_polished_AE.mat\",  {\"errors\": Err_testing, \n",
    "                                                                \"learned_sols\":Learned_sols,\n",
    "                                                                \"truth_sols\": Truth_sols\n",
    "                                                                })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d7d26",
   "metadata": {},
   "source": [
    "Initial condition encoded: torch.Size([4])\n",
    "decoded solution: (1001, 256)\n",
    "0.2475831567963216\n",
    "test 0 error: 0.008851457732680427\n",
    "Initial condition encoded: torch.Size([4])\n",
    "decoded solution: (1001, 256)\n",
    "0.38868711397668676\n",
    "test 1 error: 0.010535238678166069\n",
    "Initial condition encoded: torch.Size([4])\n",
    "decoded solution: (1001, 256)\n",
    "0.42201450073533797\n",
    "test 2 error: 0.009247118355709578\n",
    "Initial condition encoded: torch.Size([4])\n",
    "decoded solution: (1001, 256)\n",
    "0.6096916724260248\n",
    "test 3 error: 0.017053969200681543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49760a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
